{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using Resnet-152 network for training the Intel Image Classification (multi-class image classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('categories.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from os.path import exists\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizing the dataset\n",
    "data_dir = '/classification'\n",
    "train_dir = data_dir + '/seg_train'\n",
    "valid_dir = data_dir + '/seg_test'\n",
    "nThreads = 4\n",
    "batch_size = 32\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your transforms for the training and validation sets\n",
    "# Data augmentation and normalization for training\n",
    "data_transforms = {\n",
    "    'seg_train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'seg_test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "\n",
    "data_dir =\"classification\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['seg_train', 'seg_test']}\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['seg_train', 'seg_test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['seg_train', 'seg_test']}\n",
    "\n",
    "class_names = image_datasets['seg_train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train your network\n",
    "\n",
    "# 1. Load resnet-152 pre-trained network\n",
    "model = models.resnet152(pretrained=True)\n",
    "# Freeze parameters so we don't backprop through them\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#Let's check the model architecture:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a new, untrained feed-forward network as a classifier, using ReLU activations\n",
    "\n",
    "# Our input_size matches the in_features of pretrained model\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# Creating the classifier ordered dictionary first\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(2048, 512)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(512, 6)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "# Replacing the pretrained model classifier with our classifier\n",
    "model.fc = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['seg_train', 'seg_test']:\n",
    "            if phase == 'seg_train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'seg_train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'seg_train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'seg_test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid accuracy: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model with a pre-trained network\n",
    "num_epochs = 15\n",
    "if use_gpu:\n",
    "    print (\"Using GPU: \"+ str(use_gpu))\n",
    "    model = model.cuda()\n",
    "\n",
    "# NLLLoss because our output is LogSoftmax\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Adam optimizer with a learning rate\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "\n",
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do validation on the test set\n",
    "def test(model, dataloaders, device):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for images, labels in dataloaders['seg_test']:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "        print(\"Testing Accuracy: {:.3f}\".format(accuracy/len(dataloaders['seg_test'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, dataloaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the checkpoint \n",
    "\n",
    "model.class_to_idx = dataloaders['seg_train'].dataset.class_to_idx\n",
    "model.epochs = num_epochs\n",
    "checkpoint = {'input_size': [3, 224, 224],\n",
    "                 'batch_size': dataloaders['seg_train'].batch_size,\n",
    "                  'output_size': 39,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'data_transforms': data_transforms,\n",
    "                  'optimizer_dict':optimizer.state_dict(),\n",
    "                  'class_to_idx': model.class_to_idx,\n",
    "                  'epoch': model.epochs}\n",
    "torch.save(checkpoint, 'classification90.9_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = models.resnet152()\n",
    "    \n",
    "    # Our input_size matches the in_features of pretrained model\n",
    "    input_size = 2048\n",
    "    output_size = 39\n",
    "    \n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(2048, 512)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          #('dropout1', nn.Dropout(p=0.2)),\n",
    "                          ('fc2', nn.Linear(512, 6)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "# Replacing the pretrained model classifier with our classifier\n",
    "    model.fc = classifier\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model, checkpoint['class_to_idx']\n",
    "\n",
    "# Get index to class mapping\n",
    "loaded_model, class_to_idx = load_checkpoint('classification90.9_checkpoint.pth')\n",
    "idx_to_class = { v : k for k,v in class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "\n",
    "    size = 256,256\n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    image = image.crop((128 - 112, 128 - 112, 128 + 112, 128 + 112))\n",
    "    npImage = np.array(image)\n",
    "    npImage = npImage/255.\n",
    "        \n",
    "    imgA = npImage[:,:,0]\n",
    "    imgB = npImage[:,:,1]\n",
    "    imgC = npImage[:,:,2]\n",
    "    \n",
    "    imgA = (imgA - 0.485)/(0.229) \n",
    "    imgB = (imgB - 0.456)/(0.224)\n",
    "    imgC = (imgC - 0.406)/(0.225)\n",
    "        \n",
    "    npImage[:,:,0] = imgA\n",
    "    npImage[:,:,1] = imgB\n",
    "    npImage[:,:,2] = imgC\n",
    "    \n",
    "    npImage = np.transpose(npImage, (2,0,1))\n",
    "    \n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # Implement the code to predict the class from an image file\n",
    "    \n",
    "    image = torch.FloatTensor([process_image(Image.open(image_path))])\n",
    "    model.eval()\n",
    "    output = model.forward(Variable(image))\n",
    "    pobabilities = torch.exp(output).data.numpy()[0]\n",
    "    \n",
    "\n",
    "    top_idx = np.argsort(pobabilities)[-topk:][::-1] \n",
    "    top_class = [idx_to_class[x] for x in top_idx]\n",
    "    top_probability = pobabilities[top_idx]\n",
    "\n",
    "    return top_probability, top_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "x=os.listdir('seg_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in x:\n",
    "    z=predict('seg_pred/'+i, loaded_model)\n",
    "    preds.append((z[1][0],z[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image along with the top 5 classes\n",
    "def view_classify(img, probabilities, classes, mapper):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    img_filename = img.split('/')[-2]\n",
    "    img = Image.open(img)\n",
    "    plt.ion()\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n",
    "\n",
    "    ax1.imshow(img)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    y_pos = np.arange(len(probabilities))\n",
    "    ax2.barh(y_pos, probabilities)\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels([mapper[x] for x in classes])\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first 20 images of the prediction set with their probabilities.\n",
    "for i in x[:20]:\n",
    "    img = 'seg_pred/'+i\n",
    "    img_filename = img.split('/')[-2]\n",
    "    p, c = predict(img, loaded_model)\n",
    "    view_classify(img, p, c, cat_to_name)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
